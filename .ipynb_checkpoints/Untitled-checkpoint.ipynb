{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c897fa9d",
   "metadata": {},
   "source": [
    "# api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c26f1-1cdb-496d-9a1f-8fd4c65e6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import os\n",
    "import uvicorn\n",
    "import copy\n",
    "import urllib\n",
    "from io import BytesIO\n",
    "from fastapi import FastAPI#, Response\n",
    "import nest_asyncio\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# import torch\n",
    "import json\n",
    "import random\n",
    "app = FastAPI()\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "#第二步导入相应的模块\n",
    "import urllib\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "default_content_position = 14\n",
    "\n",
    "document = {}\n",
    "# plot = {}\n",
    "\n",
    "def valid_plot(x):\n",
    "    if x.split(\".\")[-1] == \"ipynb\":\n",
    "        return False\n",
    "    if x.split(\".\")[-1] == \"json\":\n",
    "        return False\n",
    "    if x[0] == \".\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "@app.get(\"/list_files\")\n",
    "def list_files(filepath):\n",
    "    filepath = urllib.parse.unquote(filepath)\n",
    "    print(filepath)\n",
    "    filelist = list(filter(valid_plot, os.listdir(\"./plot\"+filepath)))\n",
    "    rtrn = []\n",
    "    for i in filelist:\n",
    "        if i == \".ipynb_checkpoints\":\n",
    "            continue\n",
    "        if i == \".git\":\n",
    "            continue\n",
    "        if i == \"__pycache__\":\n",
    "            continue\n",
    "        if i == \"Untitled.ipynb\":\n",
    "            continue\n",
    "        if \".\" in i:\n",
    "            rtrn.append({\"filename\": i, \"type\": \"file\"})\n",
    "        else:\n",
    "            rtrn.append({\"filename\": i, \"type\": \"folder\"})\n",
    "    print(rtrn)\n",
    "    return rtrn\n",
    "        \n",
    "@app.get(\"/get_pdf_pages\")\n",
    "def get_num_pages(filename):\n",
    "    \"\"\"\n",
    "    获取文件总页码\n",
    "    :param file_path: 文件路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    reader = PdfReader(filename + \".pdf\")\n",
    "    # 不解密可能会报错：PyPDF2.utils.PdfReadError: File has not been decrypted\n",
    "    if reader.is_encrypted:\n",
    "        reader.decrypt('')\n",
    "    return len(reader.pages)\n",
    "\n",
    "@app.get(\"/get_files\")\n",
    "def get_files(filename):\n",
    "#     print(filename)\n",
    "    filename = filename.split(\"#\")[0]\n",
    "    filename = urllib.parse.unquote(filename)\n",
    "    filename = filename.replace(\"plot.txt\",\"\").replace(\".txt\",\"\")\n",
    "#     filename = filename.\n",
    "    with open(\"./database.json\", \"r\", encoding=\"UTF-8\") as file:\n",
    "        document[filename] = json.load(file)[filename]\n",
    "    for i in range(len(document[filename][\"plot\"])):\n",
    "        document[filename][\"plot\"][i][\"id\"] = i\n",
    "    return document[filename][\"plot\"]\n",
    "#     rtrn = []\n",
    "#     index = 0\n",
    "#     with open(\"./\" + filename + \".txt\", \"r\") as file:\n",
    "#         lines = file.readlines()\n",
    "#     for i in lines:\n",
    "#         if i.strip() != \"\":\n",
    "#             content = i.strip()[default_content_position:]\n",
    "#             role = i.strip()[:default_content_position].strip()\n",
    "#             rtrn.append({\"content\": content, \"role\": role,  \"id\":index})\n",
    "#             index += 1\n",
    "#     return rtrn\n",
    "\n",
    "# @app.get(\"/get_all_comments\")\n",
    "# def get_all_comments():\n",
    "#     with open(\"./database.json\", \"r\", encoding=\"UTF-8\") as f:\n",
    "#         temp_document = json.load(f)\n",
    "#     temp_comment = []\n",
    "#     for i in temp_document.keys():\n",
    "#         for j in range(len(temp_document[i][\"comments\"])):\n",
    "#             print(temp_document[i][\"comments\"])\n",
    "#             print(j)\n",
    "#             print(temp_document[i][\"comments\"][j][\"filename\"])\n",
    "#             temp_document[i][\"comments\"][j][\"filename\"] = i\n",
    "#             temp_comment.append(temp_document[i][\"comments\"][j])\n",
    "#     del temp_document\n",
    "#     return temp_comment\n",
    "    \n",
    "\n",
    "@app.get(\"/get_comments\")\n",
    "def get_comments(filename):\n",
    "    global document\n",
    "    filename = filename.split(\"#\")[0]\n",
    "#     with open(\"./\" + filename + \".json\", \"r\") as f:\n",
    "    with open(\"./database.json\",\"r\",encoding=\"UTF-8\") as f:\n",
    "        document[filename][\"comments\"] = json.load(f)[filename][\"comments\"]\n",
    "    for i in range(len(document[filename][\"comments\"])):\n",
    "        document[filename][\"comments\"][i][\"id\"] = i\n",
    "    print(document[filename][\"comments\"])\n",
    "    return document[filename][\"comments\"]\n",
    "\n",
    "@app.get(\"/update_comments\")\n",
    "def update_comments(filename):\n",
    "    global document\n",
    "    filename = filename.split(\"#\")[0]\n",
    "    return document[filename][\"comments\"]\n",
    "\n",
    "@app.get(\"/add_comments\")\n",
    "def add_comments(comment, filename):\n",
    "    global document\n",
    "    filename = filename.split(\"#\")[0]\n",
    "    comment = json.loads(comment)\n",
    "    print(comment)\n",
    "    try:\n",
    "        document[filename][\"comments\"].append(comment)\n",
    "#         document[filename][\"comments\"].append({\"filename\":filename, \"id\":maxId,\"position\":position,\"content\":content, \"type\": str(type)})\n",
    "    except: \n",
    "        document[filename][\"comments\"] = [comment]\n",
    "    print(comment)\n",
    "        \n",
    "#         document[filename][\"comments\"] = [{\"filename\":filename,\"id\":maxId,\"position\":position,\"content\":content, \"type\": str(type)}]\n",
    "\n",
    "@app.get(\"/save\")\n",
    "def save(filepath):\n",
    "    global document\n",
    "    filepath = filepath.split(\"#\")[0]\n",
    "#     with open(filepath + \".json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(document[filepath], f, ensure_ascii=False)\n",
    "    with open(\"./database.json\",\"r\", encoding=\"UTF-8\") as f:\n",
    "        content = json.load(f)\n",
    "    content[filepath] = document[filepath]\n",
    "    with open(\"./database.json\",\"w\", encoding=\"UTF-8\") as f:\n",
    "        json.dump(content, f, ensure_ascii=False)\n",
    "    with open(\"./database.json\",\"r\", encoding=\"UTF-8\") as f:\n",
    "        content = json.load(f)\n",
    "    \n",
    "        \n",
    "@app.get(\"/delete_comments\")\n",
    "def delete_comments(maxId, filename):\n",
    "    global document\n",
    "    filename = filename.split(\"#\")[0]\n",
    "    print(filename)\n",
    "    for i in range(len(document[filename][\"comments\"])-1, -1, -1):\n",
    "        if int(document[filename][\"comments\"][i][\"id\"]) == int(maxId):\n",
    "            del document[filename][\"comments\"][i]\n",
    "    print(document[filename][\"comments\"])\n",
    "        \n",
    "@app.get(\"/edit_comments\")\n",
    "def edit_comments(id, content, filename):\n",
    "    global document\n",
    "#     print(id)\n",
    "    filename = filename.split(\"#\")[0]\n",
    "    for i in range(len(document[filename][\"comments\"])):\n",
    "        print(document[filename][\"comments\"][i][\"id\"])\n",
    "        print(int(document[filename][\"comments\"][i][\"id\"]) == int(id))\n",
    "        if int(document[filename][\"comments\"][i][\"id\"]) == int(id):\n",
    "            document[filename][\"comments\"][i][\"content\"] = content\n",
    "    \n",
    "# @app.get(\"/get_file_type\")\n",
    "# def get_file_type(path):\n",
    "#     if os.path.exists(path + \".txt\"):\n",
    "#         return \"txt\"\n",
    "#     elif os.path.exists(path + \".pdf\"):\n",
    "#         return \"pdf\"\n",
    "#     return \"\"\n",
    "\n",
    "# @app.get(\"/get_files_pdf\")\n",
    "# def get_files_pdf(filename):\n",
    "#     reader = PdfReader(filename + \".pdf\")\n",
    "#     # 不解密可能会报错：PyPDF2.utils.PdfReadError: File has not been decrypted\n",
    "#     if reader.is_encrypted:\n",
    "#         reader.decrypt('')\n",
    "# #     print\n",
    "\n",
    "#     page = reader.pages[0]\n",
    "#     pdf_bytes = BytesIO()\n",
    "#     pdf_writer = PdfWriter()\n",
    "#     pdf_writer.add_page(page)\n",
    "#     pdf_writer.write(pdf_bytes)\n",
    "#     pdf_bytes.seek(0)\n",
    "\n",
    "    \n",
    "# #     return \n",
    "#     response = Response(content=pdf_bytes.getvalue(), media_type=\"application/pdf\")\n",
    "\n",
    "# #     设置响应头，告诉浏览器以附件形式保存文件\n",
    "# #     response.headers[\"Content-Disposition\"] = f\"attachment; filename={path}.pdf\"\n",
    "\n",
    "#     return response\n",
    "\n",
    "@app.get(\"/add_answer\")\n",
    "def add_answer(target_filename, target_id, answer_filename, answer_id):\n",
    "    if (target_filename == answer_filename and target_id == answer_id):\n",
    "        return\n",
    "    with open(\"./database.json\", \"r\") as f:\n",
    "        temp_document = json.load(f)\n",
    "    print(temp_document[answer_filename][\"comments\"])\n",
    "    print(answer_id)\n",
    "    temp_solution = copy.deepcopy(temp_document[answer_filename][\"comments\"][int(answer_id)])\n",
    "    temp_solution1 = copy.deepcopy(temp_document[target_filename][\"comments\"][int(target_id)])\n",
    "    try:\n",
    "        del temp_solution[\"solution\"]\n",
    "    except:\n",
    "        print(1)\n",
    "    try:\n",
    "        del temp_solution1[\"solution\"]\n",
    "    except:\n",
    "        print(1)\n",
    "    try:\n",
    "        if temp_solution not in temp_document[target_filename][\"comments\"][int(target_id)][\"solution\"]:\n",
    "            temp_document[target_filename][\"comments\"][int(target_id)][\"solution\"].append(temp_solution)\n",
    "    except:\n",
    "        temp_document[target_filename][\"comments\"][int(target_id)][\"solution\"]=[temp_solution]\n",
    "    try:\n",
    "        if temp_solution1 not in temp_document[answer_filename][\"comments\"][int(answer_id)][\"solution\"]:\n",
    "            temp_document[answer_filename][\"comments\"][int(answer_id)][\"solution\"].append(temp_solution1)\n",
    "    except:\n",
    "        temp_document[answer_filename][\"comments\"][int(answer_id)][\"solution\"]=[temp_solution1]\n",
    "#     temp_document[answer_filename][\"comments\"][int(answer_id)][\"solution\"]=list(set(temp_document[answer_filename][\"comments\"][int(answer_id)][\"solution\"]))\n",
    "    with open(\"./database.json\", \"w\") as f:\n",
    "        json.dump(temp_document, f, ensure_ascii=False)\n",
    "    del temp_solution\n",
    "    del temp_document\n",
    "\n",
    "@app.get(\"/get_answer\")\n",
    "def get_answer(target_filename, target_id):\n",
    "    with open(\"./database.json\", \"r\") as f:\n",
    "        temp_document = json.load(f)\n",
    "        try:\n",
    "            return temp_document[target_filename][\"comments\"][int(target_id)][\"solution\"]\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "@app.get(\"/delete_answer\")\n",
    "def delete_answer(target_filename, target_id, answer_filename, answer_id):\n",
    "    with open(\"./database.json\", \"r\") as f:\n",
    "        temp_document = json.load(f)\n",
    "    index = 0\n",
    "    while temp_document[target_filename][\"comments\"][int(target_id)][\"solution\"][index][\"filename\"] != answer_filename and temp_document[target_filename][\"comments\"][int(target_id)][\"solution\"][index][\"id\"] != answer_id:\n",
    "        index+=1\n",
    "    del temp_document[target_filename][\"comments\"][int(target_id)][\"solution\"][index]\n",
    "    index = 0\n",
    "    while temp_document[answer_filename][\"comments\"][int(answer_id)][\"solution\"][index][\"filename\"] != target_filename and temp_document[answer_filename][\"comments\"][int(answer_id)][\"solution\"][index][\"id\"] != target_id:\n",
    "        index+=1\n",
    "    del temp_document[answer_filename][\"comments\"][int(answer_id)][\"solution\"][index]\n",
    "    with open(\"./database.json\", \"w\") as f:\n",
    "        json.dump(temp_document, f, ensure_ascii=False)\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 运行fastapi程序\n",
    "    nest_asyncio.apply()\n",
    "    uvicorn.run(app, host='127.0.0.1', port = 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abb254",
   "metadata": {},
   "source": [
    "# 爬虫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ea987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "all_plot_url = \"https://prts.wiki/w/%E5%89%A7%E6%83%85%E4%B8%80%E8%A7%88\"\n",
    "res = requests.get(all_plot_url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "mainDiv = soup.find_all(\"div\", class_='nomobile')\n",
    "mainDiv = mainDiv[-1]\n",
    "tables = mainDiv.find_all(\"table\", recursive=False)\n",
    "string = \"https://prts.wiki/index.php?title={name}&action=edit\"\n",
    "all_plot = []\n",
    "hashmap = {}\n",
    "for i in tables:\n",
    "    tbody = i.find_all(\"tbody\", recursive=False)[0]\n",
    "#     print(tbody.find_all(\"tr\", recursive=False))\n",
    "    tr = tbody.find_all(\"tr\", recursive=False)[0]\n",
    "#     print(tr)\n",
    "    td = tr.find_all(\"td\",recursive=False)[0]\n",
    "    table = td.find_all(\"table\",recursive=False)[0]\n",
    "    tbody = table.find_all(\"tbody\",recursive=False)[0]\n",
    "    trs = tbody.find_all(\"tr\",recursive=False)\n",
    "    for i in trs:\n",
    "        title = i.find_all(\"th\",class_=\"navbox-group\",recursive=False)\n",
    "        if title == None or title == []:\n",
    "            continue\n",
    "        title = title[0].text\n",
    "        td = i.find_all(\"td\",recursive=False)[0]\n",
    "        table = td.find_all(\"table\",recursive=False)[0]\n",
    "        tbody = table.find_all(\"tbody\",recursive=False)[0]\n",
    "        trs = tbody.find_all(\"tr\",recursive=False)\n",
    "        for tr in trs:\n",
    "            th = tr.find_all(\"th\",recursive=False)\n",
    "            if th == []:\n",
    "                continue\n",
    "            th = th[0]\n",
    "            chapter = th.text\n",
    "            td = tr.find_all(\"td\",recursive=False)[0]\n",
    "            div = td.find_all(\"div\",recursive=False)[0]\n",
    "            lis = div.find_all(\"li\",recursive=False)\n",
    "            for i in lis:\n",
    "                a = i.find_all(\"a\",recursive=False)[0]\n",
    "                if title==\"集成战略\" or title==\"特殊\":\n",
    "                    if title+\"/\"+chapter not in hashmap.keys():\n",
    "                        hashmap[title+\"/\"+chapter] = 0\n",
    "                    hashmap[title+\"/\"+chapter] += 1\n",
    "                    all_plot.append({\"filename\":\"./plot/\"+title+\"/\"+chapter+\"/\"+str(hashmap[title+\"/\"+chapter])+\"_\"+a.text.replace(\" \",\"_\"), \"href\":urllib.parse.unquote(string.format(name=a.get(\"href\")[3:]))})\n",
    "                else:\n",
    "                    if chapter+\"/\"+title not in hashmap.keys():\n",
    "                        hashmap[chapter+\"/\"+title] = 0\n",
    "                    hashmap[chapter+\"/\"+title] += 1\n",
    "#                     print(\"./plot/\"+chapter+\"/\"+title+\"/\"+str(hashmap[chapter+\"/\"+title])+\"_\"+a.text.replace(\" \",\"_\"), urllib.parse.unquote(string.format(name=a.get(\"href\")[3:])))\n",
    "                    all_plot.append({\"filename\":\"./plot/\"+chapter+\"/\"+title+\"/\"+str(hashmap[chapter+\"/\"+title])+\"_\"+a.text.replace(\" \",\"_\"), \"href\": urllib.parse.unquote(string.format(name=a.get(\"href\")[3:]))})\n",
    "\n",
    "all_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9cfb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i[\"filename\"]+\".txt\" for i in all_plot]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "exception = []\n",
    "for i in all_plot:\n",
    "#     if i[\"filename\"].split(\"/\")[2] != \"剧情\":\n",
    "#         continue\n",
    "    print(i)\n",
    "    paths = i[\"filename\"].split(\"/\")\n",
    "    for j in range(1,len(paths)):\n",
    "        path = \"/\".join(paths[:j])\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "    with open(i[\"filename\"]+\".txt\",\"w\") as f:\n",
    "        res = requests.get(i[\"href\"])\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        try:\n",
    "            f.write(soup.find(\"textarea\").text)\n",
    "        except:\n",
    "            exception.append(i[\"filename\"])\n",
    "    print(i[\"filename\"])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "total_plot = {}\n",
    "def parse_sentence(text):\n",
    "    sentence_pattern = r'\\[name=\"([^\"]+)\"\\](.+)'    \n",
    "    decision_pattern = r'\\[Decision\\(options=\"([^\"]+)\",values=\"([^\"]+)\"\\)\\]'\n",
    "    preference_pattern = r'\\[Predicate\\(references=\"([^\"]+)\"'\n",
    "    subtitle_pattern = r'\\(text=\"([^\"]+)\"\\] (.+)'\n",
    "#     print(text)\n",
    "    if re.match(sentence_pattern, text):\n",
    "        match = re.match(sentence_pattern, text)\n",
    "        character_name = match.group(1)\n",
    "        sentence = match.group(2)\n",
    "        return character_name, [sentence]\n",
    "    elif re.match(decision_pattern, text):\n",
    "        match = re.match(decision_pattern, text)\n",
    "        options = match.group(1).split(\";\")\n",
    "        values = match.group(2).split(\";\")\n",
    "        return \"  选择\", [f\"{i[0]} (分支{i[1]})\" for i in list(zip(options, values))]\n",
    "    elif re.match(preference_pattern, text):\n",
    "        match = re.match(preference_pattern, text)\n",
    "        return f\"分支{match.group(1)}\", [\"\"]\n",
    "    elif re.match(subtitle_pattern, text):\n",
    "        match = re.match(subtitle_pattern, text)\n",
    "        return \"旁白\", [match.group(1)]\n",
    "def write_files(filename):\n",
    "    write_txt = open(filename.replace(\".txt\",\"plot.txt\"), \"w\")\n",
    "    write_json = open(filename.replace(\".txt\",\".json\"),\"w\")\n",
    "    temp_dict = []\n",
    "#     filename = \n",
    "    name = \"/\".join(filename.replace(\".txt\",\"\").replace(\"./plot/\",\"\").split(\"/\")[:-1]) +\"/\"+ \"_\".join(filename.replace(\".txt\",\"\").replace(\"./plot/\",\"\").split(\"/\")[-1].split(\"_\")[1:])\n",
    "#     print(name)\n",
    "    total_plot[name] = {}\n",
    "    total_plot[name][\"plot\"] = []\n",
    "    total_plot[name][\"comments\"] = []\n",
    "    with open(filename, \"r\", encoding=\"UTF-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            sentence = parse_sentence(line)\n",
    "#             print(sentence)\n",
    "            if not sentence:\n",
    "                continue\n",
    "            role, sentence = sentence\n",
    "            role += \":\"\n",
    "            for i in sentence:\n",
    "                temp_dict.append({\"role\":role,\"content\":i})\n",
    "                while len(role) < 20:\n",
    "                    role += \" \"\n",
    "                write_txt.write(role)\n",
    "                write_txt.write(i)\n",
    "                write_txt.write(\"\\n\")\n",
    "                role = \"\"\n",
    "            total_plot[name][\"plot\"] = temp_dict\n",
    "    json.dump(temp_dict, write_json, ensure_ascii=False)\n",
    "    write_txt.close()\n",
    "    write_json.close()\n",
    "# write_files(\"./plot/支线/不义之财/1_CV-ST-1_火线之中.txt\")          \n",
    "for path, folder, file in os.walk(\"./plot\"):\n",
    "    print(path)\n",
    "    for i in file:\n",
    "        if \".txt\" not in i or \"plot\" in i:\n",
    "            continue\n",
    "        temp_path = path +\"/\"+ i\n",
    "        write_files(temp_path)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
